\documentclass{IEEEtran}
\usepackage{hyperref}
\usepackage[latin1]{inputenc}
\usepackage[ngerman]{babel}

\title{Staukontrolle durch Active Queue Management}
\author{Thomas Fischer, Dominik Billing}
\specialpapernotice{Masterseminar Kommunikationssysteme\\
Lehr- und Forschungseinheit für Kommunikationssysteme und Systemprogrammierung\\
Ludwig-Maximilians-Universität München}

\begin{document}
\maketitle

\begin{abstract}
Dieser Artikel beschreibt die Problematik im Internet, die durch den Einsatz von konventioneller Staukontrolle in Routern und der Struktur des Internets hervorgerufen wird. Diese liegt darin, dass Pakete nicht gleichmäßig fallen gelassen werden und es auf diese Art zu großem Overhead kommt, der durch Flaschenhälse im Internet noch verstärkt wird. Zusätzlich können besonders bandbreitenhungrige Datenströme nicht sinnvoll begrenzt werden.

Wir werden als Lösung für das Problem der Staukontrolle im Internet Active Queue Management herausarbeiten. Active Queue Management versucht Staus frühzeitig und zuverlässig zu erkennen und durch Fallenlassen oder Markieren von Paketen Staus zu verhindern. Zusätzlich werden alle Datenströme gleich behandelt. Dies wird von AQM-Algorithmen erreicht, indem die mittlere Pufferauslastung von Routern möglichst gering gehalten wird.

Um einen Überblick über aktuelle AQM-Algorithmen zu erhalten, werden wir die AQM-Methoden RED, BLUE und PI vorstellen und mit untereinander und mit ECN vergleichen.
\end{abstract}

\section{Einführung und Motivation}\label{sec:Motivation}
Nach Floyd \cite{Floyd1997} sind Ende-zu-Ende (E2E) Staukontrollmechanismen von TCP mittlerweile ein kritischer Faktor in der Robustheit des Internets. Das Internet wächst unaufhaltsam weiter, es gibt keine eng verknüpfte Netzgemeinschaft mehr und nicht jeder Endknoten verwendet die E2E Staukontrolle für bestmöglichen Datenfluss. Entwickler kümmern sich nicht länger darum, E2E Staukontrolle in ihre Internet-Anwendungen zu integrieren. Die Konsequenz davon ist, dass das Netzwerk selbst seine Resourcennutzung kontrolliert.

Graffi \cite{Graffi2007} beschreibt, dass Bandbreite aktuell die knappste Ressource in Netzwerken ist. Die eingehenden und ausgehenden Bandbreiten normaler ADSL Verbindungen sind unterschiedlich. Typischerweise ist die ausgehende Bandbreite deutlich kleiner als die eingehende. Das bedeutet, dass nicht alle eingehenden Daten verarbeitet und weitergesandt werden können. Staus sind also Probleme, die hier auftreten können, wenn keine angemessenen Mechanismen angewendet werden. Das TCP-Protokoll sieht vor, Pakete nach dem "First in First out" Prinzip fallenzulassen, wenn die Puffer voll laufen.

Die Problemstellung hier ist es also Mechanismen zu finden, Staus in E2E Verbindungen zu kontrollieren. Nach Le \cite{Le2003} soll die durchschnittliche Pufferausnutzung klein gehalten werden, damit E2E-Staukontrolle ermöglicht wird. Die Herausforderung besteht darin, dass an den Flaschenhälsen der potenzielle Stau erkannt wird und das komplette Netzwerk darauf reagiert, indem beispielsweise die Sendegeschwindigkeit des Ursprungs eines Datenstroms drastisch reduziert wird \cite{Graffi2007}.

Das folgende Kapitel (Kapitel \ref{sec:Staukontrolle}) beschreibt die generellen Konzepte der Staukontrolle in Netzen und präsentiert Active Queue Management als Lösungsansatz für das Problem. In Kapitel \ref{sec:AQM} wird Active Queue Management definiert und einige Anwendungsfälle davon präsentiert. Die Active Queue Management Algorithmen RED, BLUE, ECN und PI werden in Kapitel \ref{sec:Algorithmen} vorgestellt und in Kapitel \ref{sec:Vergleich} miteinander verglichen. Ein Ausblick zu zukünftigen Entwicklungen und Forschungen sowie andere Ansätze zur Staukontrolle zusammen mit den zusammengefassten Ergebnissen erfolgt in Kapitel \ref{sec:Ausblick}.

\section{Staukontrolle in Netzen}\label{sec:Staukontrolle} 

Neben \cite{Floyd1997} wird auch von Morris \cite{Morris1997} postuliert, dass die Effektivität von TCP mit zunehmender Anzahl an konkurrierender Datenströme nachlässt. Dieser Effekt beginnt sich zu zeigen, sobald mehr Datenströme als Pakete die vorhandene Bandbreite verwenden. Diese Probleme sind auch im Internet spürbar und es zeigt sich, dass das Internet einen gravierenden Performanceverlust dadurch erfährt. Die einfachste Lösung für diese Probleme wäre die radikale Vergrößerung von Routerpuffern zusammen mit einer Begrenzung der Anzahl der Pakete jedes einzelnen Datenstroms individuell. Da dies aber nicht ausführbar ist, müssen Staukontrollalgorithmen implementiert werden, mit den folgenden Haupzielen. Es soll eine hohe Ausnutzung von Flaschenhälsen wie Routern erreicht werden. Der Überlauf von Flaschenhälsen und damit eine zeitliche Verzögerung durch Staus sowie ein hoher Paketverlust soll verhindert werden. Zusätzlich soll die zur Verfügung stehende Bandbreite gleichmäßig zwischen konkurrierenden Datenströmen aufgeteilt werden \cite{Morris1997}. Um diese gleichmäßige Verteilung zu erreichen, ist TCP standardmäßig mit dem "`First Come First Serve"'-Prinzip nicht geeignet. Deshalb müssen hierfür andere Methoden entwickelt werden, die den Puffer in Routern anders abarbeiten und dennoch einfach zu verwenden sind \cite{Suter1998}.

Die Internet Protokoll Architektur basiert auf einem verbindungslosen E2E Paketdienst, der das IP Protokoll benutzt. Die vielen Vorteile dieses verbindungslosen Designs, der Flexibilität und Robustheit wurden schon oft beschrieben. Allerdings kommen diese Vorteile zu einem Preis. Sorgfältiges Design ist benötigt, um einen guten Dienst zu leisten bei hoher Last. Fehlende Aufmerksamkeit bei den Dynamiken des Paketweiterleitens kann in ernsthafter Dienstdegradation enden oder "`Internet Zusammenbruch"' \cite{Braden1998}. Dieses Phänomen wurde während der ersten Wachstumsphase des Internets in den 1980er Jahren festgestellt und wird "`congestion collapse"' \cite{Nagle1984} genannt. Bereits 1986 wurden von Jacobson entwickelte Stauverhinderungsmechanismen für Hosts entwickelt, die auch aktuell einen "`congestion collapse"' verhindern \cite{Braden1998}.

Da das Internet seit dieser Zeit immer weiter wächst, wurde es offensichtlich, dass TCP Stauverhinderungsmechanismen \cite{Stevens1997}, die absolut wichtig, nötig und mächtig sind, nicht unter allen Umständen ausreichend gute Dienste leisten. Das Hauptproblem liegt darin, dass von den Enden der Netzwerke nur bedingt Kontrolle ausgeübt werden kann. Deshalb müssen auch in Routern Mechanismen angewendet werden, die die Stauverhinderungsmechanismen der Endpunkte ergänzen. Hierbei muss man zwischen den beiden Klassen "`Queue Management"' und "`Scheduling"' von Router Algorithmen unterscheiden. Queue management Algorithmen verwalten die Länge von Paket-Puffern durch Fallenlassen von Paketen wenn nötig oder angemessen. Scheduling Algorithmen legen fest, welche Pakete als nächstes gesendet werden sollen und können primär dafür genutzt werden, die Zuweisung von Bandbreite zwischen den Datenströmen zu verwalten \cite{Braden1998}.

Nach Jain \cite{Jain1990} gibt es zwei Gründe, warum das Problem der Staukontrolle in Netzwerken sehr schwierig ist. Erstens gibt es Voraussetzungen für Staukontroll Schemas, die es schwierig machen eine zufriedenstellende Lösung zu finden. Zweitens gibt es unzählige Netzwerkregeln, die das Design eines Stauschemas beeinflussen. Das sind die Gründe, warum ein Schema, das für ein Netzwerk entwickelt wurde, in einem anderen Netzwerk nicht funktioniert. Grundbedingung für Schemas zur Staukontrolle sind: Das Schema muss einen kleinen Overhead haben, alle Datenströme gleichbehandeln, schnell auf andere Situationen reagieren können, in schlechten Umgebungen funktionsfähig sein und für alle Benutzer optimal sein.

Um E2E-Staukontrolle in Routern zu betreiben, muss nicht nur jeder einzelne Router auf sich allein gestellt seinen Puffer überwachen, sondern auch an die nächsten Router Informationen weiterleiten. Für diese Benachrichtigung könnten zwei reservierte Bits im TCP/IP-Header genutzt werden \cite{Graffi2007}. Mittels "`Explicit Congestion Notification"' (ECN) sollen Pakete mit der Staubenachrichtigung weiterversandt werden im Gegensatz zum einfachen Fallenlassen der Pakete. Auf diese Art und Weise werden vorangehende Router darüber informiert, dass es zu einem Stau gekommen ist und möglicherweise einzelne Pakete doppelt versandt werden müssen oder die Geschwindigkeit gedrosselt werden sollte. Prinzipiell ist es in Netzwerken, in denen es die Hauptaufgabe von Routern ist, Pakete an den Output-Port weiterzuleiten, kein Problem Pakete einfach fallen zulassen. Dies ist allerdings im Internet heute nicht mehr der Fall, da E2E-Verbindungen über sehr viele Router gehen können. ECN ist ein zuverlässiger Mechanismus, beinhaltet allerdings keine Methoden zur Erkennung von Staus \cite{Floyd1994}. Da es nicht vorhersehbar ist, wie hoch der Datenverkehr zukünftig sein wird, besteht das wirkliche Problem also darin, Staus frühzeitig und zuverlässig zu erkennen \cite{Jain1996}.

Router sollten den Ursprüngen eines Datenstrom signalisieren, dass die Sendegeschwindigkeit reduziert werden muss, um Staus zu vermeiden. Zusätzlich kann so eine gleichmäßige Verteilung der Bandbreite erfolgen, wenn besonders gierige Datenströme vorhanden sind. "`Active Queue Management"' (AQM) hat das Ziel Staus in Netzwerken rechtzeitig zu entdecken, bevor die Routerpuffer volllaufen. Es gibt im Prinzip zwei Möglichkeiten andere Router darüber zu informieren, dass ein Stau bevorsteht: Pakete können fallengelassen oder markiert werden. Die erste Strategie erfordert, dass die Endpunkte kooperieren und erzeugt einen Overhead, weil Pakete anschließend erneut gesendet werden müssen. Endpunkte müssen auf markierte Pakete reagieren, als wären sie fallengelassen worden, allerdings wird hier kein weiterer Overhead erzeugt, da die Pakete nicht erneut gesendet werden müssen. AQM-Algorithmen können zusätzlich die Bandbreite von besonders gierigen Datenströmen reduzieren, indem deren Pakete häufiger fallengelassen werden \cite{Graffi2007}.

\section{Definition und Anwendung von Active Queue Management}\label{sec:AQM}
\begin{itemize}
\item Wirklich gute Quelle hierfür ist \cite{Braden1998} Kapitel 2 \textbf{\textit{wirklich sehr gute Quelle}}
\item Effizientes Active Queue Management in Internet Routern \cite{Suter1998a}
\item Dimensionierung von Router Puffern \cite{Appenzeller2004}
\item Stochastische Modellierung und die Theorie von Queues \cite{Wolff1998}
\item Analyse und Simulation eines gleichbehandelnden Queue Algorithmus \cite{Demers1989}
\end{itemize}



\section{Die gängigsten Active Queue Management Algorithmen}\label{sec:Algorithmen}

Seitdem die ersten Ideen für Active Queue Management vorgestellt wurden und mit der Einführung von ECN in IP/TCP wurden viele verschiedene AQM Algorithmen entwickelt. Es würde weit über den Rahmen dieser Arbeit hinausgehen, sie alle zu erwähnen, weshalb hier nur drei vorgestellt werden.

\subsection{RED: Random Early Detection}

Der erste Algorithmus, der präsentiert wird, ist Random Early Detection (RED). Er war einer der ersten AQM Algorithmen und viele andere Arbeiten entwickelten diesen weiter wie z.B. in \cite{Floyd2001} oder \cite{Pan2000}. Andererseits werden Algorithmen, die anders ablaufen, oft mit RED verglichen.

Floyd und Van Jacobson haben RED 1993 vorgestellt \cite{Floyd1993}. In ihrer Arbeit wird die Funktionsweise des Algorithmus dargestellt. Um die Sender über die Verstopfung zu informieren kann RED entweder Pakete fallen lassen oder das ECN-Bit im Header setzen, je nach Router. Im folgenden werden wir nur die Möglichkeit des Markierens betrachten, was auf den eigentlichen Algorithmus keinerlei Auswirkungen hat. Als Messgröße wird die durchschnittliche Queue Länge benutzt. Die durchschnittliche Länge \textit{Q$_{avg}$} wird für jedes eintreffende Paket mittels der aktuellen Länge der Queue \textit{q} und dem Gewicht der Queue \textit{w$_{q}$} folgendermaßen neu berechnet: \( Q_{avg} = (1 - w_q) Q_{avg} + w_q q\). Dieser Wert wird mit zwei Parametern verglichen, der minimalen Queuelänge \textit{Q$_{min}$} und der maximalen Queuelänge \textit{Q$_{max}$}. Ist \(Q_{min} > Q_{avg}\), so wird nichts unternommen. Wird aber \(Q_{min} < Q_{avg} < Q_{max}\), so wird das Paket mit einer Markierungswahrscheinlichkeit \textit{p$_a$} markiert, und sobald \(Q_{avg} > Q_{max}\) wird jedes Paket markiert.

Für die Berechnung der finalen Markierungswahrscheinlichkeit \textit{p$_{a}$} wird die Markierungswahrscheinlichkeit \textit{p$_{b}$} benötigt. Diese berechnet sich wie folgt aus der minimalen und maximalen Queuelänge \textit{Q$_{min}$} und \textit{Q$_{max}$}, der Durchschnittslänge \textit{Q$_{avg}$} und dem Maximum für \textit{p$_{b}$}, \textit{max$_{b}$}, wie folgt: \(p_b = max_p \frac{Q_{avg} - Q_{min}}{Q_{max} - Q_{min}}\). \textit{p$_{b}$} steigt folglich linear von 0 bis zum Wert \textit{max$_{b}$} an. Die finale Markierungswahrscheinlichkeit wird mittels \textit{p$_{b}$} und eines Zählers \textit{z} berechnet: \(p_a = \frac{p_b}{1-z p_b}\). Der Zähler wird für jedes einkommende Paket inkremetiert. Ein Paket wird mit der Wahrscheinlichkeit \textit{p$_a$} markiert. Ist dies der Fall, so wird der \textit{z} auf 0 gesetzt. Mithilfe des Zählers steigt die Wahrscheinlichkeit somit für jedes weitere Paket an.

Die Markierungswahrcheinlichkeit für ein Paket einer Verbindung verhält sich also in etwa proportional zum Anteil der Bandbreite, den diese Verbindung belegt. Auf diese Weise versucht der Algorithmus die Resourcenzuteilung fair zu machen. Neben der Queuelänge in Paketen könnte RED auch die Bytelänge und somit die Anzahl an Bytes eines Pakets zur Bewertung heranziehen. Diese Information wird dann in den Markierungswahrscheinlichkeit \textit{p$_b$} mit einbezogen. Nach der Berechnung ändert sich der Wert dann in \(p_b = p_b \frac{Paketbytes}{maximale Paketbytes}\). Dadurch werden große Pakete mit einer höheren Warscheinlichkeit markiert als kleine Pakete. An der Beschreibung des Algorithmus wird ersichtlich, dass RED viele Parameter benötigt, die vorab festgelegt werden müssen. Damit RED gut läuft, müssen für jeden Router die richtigen Werte gefunden werden, was ein nicht zu vernachlässigendes Problem des Algorithmus darstellt. Mehr dazu in Abschnitt \ref{sec:Vergleich}.

\subsection{BLUE}

Der BLUE Algorithmus wurde 1999 von Feng et.al. an der University of Michigan in Zusammenarbeit mit IBM vorgestellt \cite{BLUE1999}. BLUE wurde entwickelt, um einige Schwachstellen von RED zu verbessern, ist aber ein völlig neuer Ansatz. Wie bereits erläutert verlässt sich RED auf die Queuelänge, um Verstopfungen anzuzeigen, und benötigt viele Parameter, die konfiguriert werden müssen. Die Autoren von BLUE argumentieren, dass RED nur wenn diese richtig konfiguriert sind und wenn ausreichend Pufferplatz zur Verfügung steht optimal läuft. BLUE dagegen verlässt sich auf den Paketverlust und die Verbindungsauslastung um seine Markierungswahrscheinlichkeiten zu berechnen. Genause wie RED kann BLUE dann entweder Pakete fallen lassen oder mittels ECN markieren.

Der BLUE Algorithmus kennt nur eine Markierungswahrscheinlichkeit \textit{p$_m$}; jedes einzureihende Paket wird mit dieser Wahrscheinlichkeit markiert. Die Entscheidung für die Erhöhung oder Erniedrigung dieser Wahrscheinlichkeit wird auf Basis der verlorenen Pakete beziehungsweise auf Basis der ungenutzten Verbindungen getroffen: Erhält der Router die Information, dass ein Paket verloren gegangen ist, wird \textit{p$_m$} um den Wert \textit{d$_1$} erhöht. Erkennt er eine ungenutzte Verbindung, wird \textit{p$_m$} um \textit{d$_2$} reduziert. Ein weiterer Parameter ist hierbei noch wichtig: die \textit{freeze\_time}. Damit das Netz und die Sender Zeit haben, auf die Aktion des Routers zu reagieren, muss mindestens dieses Zeitintervall vergangen sein, bis die Markierungswahrscheinlichkeit wieder geändert wird. Formal läuft der Algorithmus folgendermaßen ab:
\newline \(if(Paketverlust \wedge (now - last\_update) > freeze\_time)~then\)
\newline \indent \(p_m = p_m + d_1\)
\newline \indent \(last\_update = now\)
\newline \(if(Verbindung~frei \wedge (now - last\_update > freeze\_time))~then\)
\newline \indent \(p_m = p_m - d_2\)
\newline \indent \(last\_update = now\)

Die beiden Parameter \textit{d$_1$} und \textit{d$_2$} geben an, um wie viel \textit{p$_m$} zu erhöhen beziehungsweise zu reduzieren ist. \textit{d$_1$} sollte deutlich größer sein als \textit{d$_2$}, da BLUE somit auf Verstopfungen sehr viel schneller reagieren kann. Die Autoren geben weiterhin an, dass in ihren Experimenten die minimale Zeitspanne zwischen Änderungen an \textit{p$_m$}, die \textit{freeze\_time}, konstant gehalten wurde. Sie sagen aber auch, dass in einem Netz dieser Parameter zufällig für jeden Router gewählt werden sollte, um globale Synchronisation zu vermeiden. Dieser Algorithmus passt sich somit selbstständig an den aktuellen Bedarf des Netzes an und benötigt keine Router-abhängigen Parameter zur Konfiguration.

\subsection{AVQ: Adaptive Virtual Queue}

Ein weiterer AQM-Algorithmus, der eine andere Idee verfolgt, ist der Adaptive Virtual Queue (AVQ) Algorithmus. Er wurde 2001 von Kunniyur und Srikant vorgestellt \cite{Kunniyur2001}. Wie bereits der Name andeutet basiert der Algorithmus auf einer virtuellen Queue. Für die Markierung beziehungsweise das Fallenlassen von Paketen wird die Kapazität dieser virtuellen Queue und keine Markierungswahrscheinlichkeit zu Rate gezogen.

Bei AVQ verwaltet der Router neben der echten Queue eine virtuelle Queue mit der Kapazität \(C_v \le C\), wobei \textit{C} die Kapazität der Verbindung ist. Zu Beginn ist \(C_v = C\). Bei jedem ankommenden Paket wird überprüft, ob der Puffer der virtuellen Queue das Paket aufnehmen könnte. Ist dem so, wird das echte Paket in die tatsächliche Queue eingereiht, ansonsten wird es markiert oder fallen gelassen. Die Kapazität der virtuellen Queue wird ebenfalls bei jedem ankommenden Paket angepasst gemäß der Differentialgleichung \(\dot{C_v} = \alpha(\gamma C - \lambda)\) wobei \(\alpha\) ein Glättungsparameter, \(\gamma\) die angestrebte Auslastung der Verbindung und \(\lambda\) die Ankunftsrate der Verbindung ist. Das Markieren passiert auf diese Weise aggressiver, also häufiger, wenn die Verbindung ihre gewünschte Bandbreite überschreitet und weniger aggressiv, wenn nicht.

Es ist klar, dass in der virtuellen Queue keine Pakete eingereiht werden müssen, lediglich die Länge, also die Kapazität der virtuellen Queue muss ermittelt werden. Die Autoren geben in ihrer Arbeit auch an, wie dieses Verfahren als Algorithmus konkret implementiert werden kann:
\newline Für jedes ankommende Paket DO
\newline \(VQ = max(VQ - C_v(t-s),0)\)
\newline \(if(VQ + b > B)~then\)
\newline \indent Paket markieren
\newline \textit{else}
\newline \indent \(VQ = VQ + b\)
\newline \(C_v = max(min(C_v + \alpha \cdot \gamma \cdot C(t-s),C)-\alpha \cdot b,0)\)
\newline \(s = t\)
\newline wobei \textit{B} die Puffergröße in Bytes, \textit{s} die Ankunftszeit des letzten Pakets, \textit{t} die aktuelle Zeit, \textit{b} die Paktegröße des aktuellen Pakets in Bytes und \textit{VQ} die Anzahl an Bytes, die aktuell in der virtuellen Queue sind, ist.

Die Autoren erläutern, dass die algorithmische Komplexität von AVQ in etwa der von RED entspricht. Anstelle der Länge der Queue wird bei AVQ jedoch die Ausnutzung der Queue als Entscheidungskriterium für das Markieren von Paketen verwendet. Für die Verwendung von AVQ müssen der Glättungsparameter \(\alpha\) und die gewünschte Ausnutzung \(\gamma\) vorab angegeben werden. Diese dienen der Stabilität des Verfahrens. Weiter geben die Autoren an, dass \(\gamma\) es den ISP's erlaubt einen Ausgleich zwischen hoher Bandbreitenausnutzung und kleinen Puffern vorzunehmen. Eine Regel, wie diese Parameter gesetzt werden sollten, befindet sich in der Originalarbeit in \cite{Kunniyur2001}.

\section{Vergleich der vorgestellten Algorithmen}\label{sec:Vergleich}
\begin{itemize}
\item Vergleich RED, ARED, PI \cite{Le2003}
\item Vergleich RED, PI \cite{Kunniyur2001}
\item Vergleich RED, BLUE, ARED, ECN, PI \cite{Graffi2007}
\end{itemize}



\section{Ausblick und andere Ansätze}\label{sec:Ausblick}
\begin{itemize}
\item Ein wirklich optimaler Algorithmus muss noch gefunden werden \cite{Graffi2007}
\item Statt Staukontrolle andere Wege suchen (CHOKe) \cite{Pan2000}
\end{itemize}

\nocite{*}
\bibliographystyle{IEEEtran_de}
\bibliography{IEEEabrv,bibliothek}


\end{document}
